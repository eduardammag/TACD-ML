{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e7fb8cd-82ca-4639-a941-a91146817ef5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3b79ba-6d08-4aaf-9192-28ea6d12823a",
   "metadata": {},
   "source": [
    "# Lab 08 - Virtual Screening Problem\n",
    "In this lab, your task is to create a predictive Machine Learning model that will be deployed as a Virtual Screening (VS) tool. VS is a powerful computational technique used to evaluate the desired biological activity of thousands of drug molecules. By using this technology, we can significantly reduce the time and expenses involved in the drug development pipeline.\n",
    "\n",
    "In this lab, you will take on the role of a **Machine Learning Engineer** at an innovative Pharmaceutical company. Your team has been working on identifying new treatments for Chagas disease, and your job is to train a machine learning model that can be used as a virtual screening tool to identify potential candidates for the treatment. After conducting some research, you've found a promising dataset of a detailed [_in vivo_](https://ridgewayresearch.co.uk/parasite-diagnostics-laboratory/in-vitro-in-vivo-assays/#:~:text=In%20vivo%20assays%20are%20used,Assess%20their%20safety) assay where thousands of molecules were evaluated to determine their biological activity in suppressing Trypanosoma Cruzi, the causal agent of Chagas disease. With your team, you've decided that this high-quality dataset can be used to train the machine learning model.\n",
    "\n",
    "Your team of **Feature Engineers** has extracted different types of molecular features that describe these drug molecules and has generated the following dataset: `cruzi_comp_activity_molecular_features.csv`. However, they've also informed you that for some molecules, some molecular features, specifically \"NumberOfAromaticRings\" and \"TPSA\", couldn't be extracted. It's now up to you, the ML Engineer, to decide how to handle this issue.\n",
    "\n",
    "The outcome of the in vivo assay is recorded in the \"EC50\" column of the dataset. According to the report, any molecule with an EC50 activity of less than or equal to 1 $\\mu M$ is considered active. This means that for a molecule to be deemed active, its EC50 value must be no greater than 1 $\\mu M$. These active molecules can then be prioritized as potential candidates for a new treatment against Chagas disease.\n",
    "\n",
    "You will need to analyze the data, consider the problem at hand, and decide whether to train a regression or a classification model. You will also need to select a correct and relevant performance metric for your model(s).\n",
    "\n",
    "Please note that you are free to use any of the algorithms that were covered in the class for both regression and classification tasks. However, you must not import any other classifiers, such as Random Forests, XgBoost, or any other algorithm not covered in the class.\n",
    "\n",
    "The task for today is analyse the performance of the different methods when applied to this interesting real-life problem, and obtain the best predictive model. As a side task, you can compare your own implementations of the algorithms with the sklearn ones and see if they behave in the same way and if they don't then try to think what could be causing these differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb97cd1a-34fc-47c5-a059-a1c3127a2f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "mol_df = pd.read_csv('cruzi_comp_activity_molecular_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e74f8ba9-26fb-45c0-bd01-acb659e09cb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(CID                           0\n",
       " NumberOfRings                 0\n",
       " NumberOfAromaticRings        10\n",
       " ALogP                         0\n",
       " MolecularWeight               0\n",
       " RotatableBondCount            0\n",
       " HydrogenBondAcceptorCount     0\n",
       " HydrogenBondDonorCount        0\n",
       " TPSA                         10\n",
       " XlogP                         0\n",
       " EC50                          0\n",
       " dtype: int64,\n",
       "                 CID  NumberOfRings  NumberOfAromaticRings        ALogP  \\\n",
       " count  3.854000e+03    3854.000000            3844.000000  3854.000000   \n",
       " mean   7.376335e+06       3.473534               2.702133     0.016681   \n",
       " std    7.612063e+06       1.087264               0.961927     0.260351   \n",
       " min    1.201000e+03       0.000000               0.000000     0.000000   \n",
       " 25%    2.157768e+06       3.000000               2.000000     0.000000   \n",
       " 50%    3.582156e+06       3.000000               3.000000     0.000000   \n",
       " 75%    1.200559e+07       4.000000               3.000000     0.000000   \n",
       " max    5.664295e+07       9.000000               6.000000     6.240000   \n",
       " \n",
       "        MolecularWeight  RotatableBondCount  HydrogenBondAcceptorCount  \\\n",
       " count      3854.000000         3854.000000                3854.000000   \n",
       " mean        397.303790            5.401401                   5.110275   \n",
       " std          82.529086            2.549791                   2.009718   \n",
       " min         149.212880            0.000000                   0.000000   \n",
       " 25%         340.935825            4.000000                   4.000000   \n",
       " 50%         395.498730            5.000000                   5.000000   \n",
       " 75%         447.593620            7.000000                   6.000000   \n",
       " max        1246.635480           48.000000                  19.000000   \n",
       " \n",
       "        HydrogenBondDonorCount         TPSA        XlogP         EC50  \n",
       " count             3854.000000  3844.000000  3854.000000  3854.000000  \n",
       " mean                 1.079398    81.793184     3.257758     1.948531  \n",
       " std                  0.867815    36.135527     1.714814     5.478799  \n",
       " min                  0.000000     0.000000    -0.700000     0.100000  \n",
       " 25%                  0.000000    55.400000     2.500000     0.451250  \n",
       " 50%                  1.000000    79.200000     3.600000     1.126500  \n",
       " 75%                  2.000000   106.000000     4.500000     2.040000  \n",
       " max                  7.000000   330.000000     8.600000    60.000000  ,\n",
       " {'accuracy': 0.6342412451361867,\n",
       "  'precision': 0.6395759717314488,\n",
       "  'recall': 0.5013850415512465,\n",
       "  'f1_score': 0.562111801242236},\n",
       " {'accuracy': 0.6316472114137484,\n",
       "  'precision': 0.6379928315412187,\n",
       "  'recall': 0.4930747922437673,\n",
       "  'f1_score': 0.55625})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificar valores ausentes e estatísticas básicas\n",
    "missing_values = mol_df.isnull().sum()\n",
    "statistics = mol_df.describe()\n",
    "\n",
    "# Tratar valores ausentes imputando com a média de cada coluna\n",
    "mol_df['NumberOfAromaticRings'].fillna(mol_df['NumberOfAromaticRings'].mean(), inplace=True)\n",
    "mol_df['TPSA'].fillna(mol_df['TPSA'].mean(), inplace=True)\n",
    "\n",
    "# Criar uma variável alvo binária\n",
    "mol_df['Active'] = mol_df['EC50'] <= 1\n",
    "\n",
    "# Dividir as features e a variável alvo\n",
    "X = mol_df.drop(columns=['EC50', 'Active'])\n",
    "y = mol_df['Active']\n",
    "\n",
    "# Dividir o dataset em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Padronizar as features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Treinar e avaliar a Regressão Logística do sklearn\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_log_reg = log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Implementação manual da Regressão Logística\n",
    "class ManualLogisticRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=1000):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.m, self.n = X.shape\n",
    "        self.weights = np.zeros(self.n)\n",
    "        self.bias = 0\n",
    "\n",
    "        for _ in range(self.n_iterations):\n",
    "            linear_model = np.dot(X, self.weights) + self.bias\n",
    "            y_predicted = self.sigmoid(linear_model)\n",
    "\n",
    "            dw = (1 / self.m) * np.dot(X.T, (y_predicted - y))\n",
    "            db = (1 / self.m) * np.sum(y_predicted - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "\n",
    "    def predict(self, X):\n",
    "        linear_model = np.dot(X, self.weights) + self.bias\n",
    "        y_predicted = self.sigmoid(linear_model)\n",
    "        y_predicted_class = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "        return y_predicted_class\n",
    "\n",
    "# Treinar e avaliar a implementação manual da Regressão Logística\n",
    "manual_log_reg = ManualLogisticRegression(learning_rate=0.01, n_iterations=1000)\n",
    "manual_log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred_manual_log_reg = manual_log_reg.predict(X_test_scaled)\n",
    "\n",
    "# Função para avaliar os modelos\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# Avaliar os modelos\n",
    "results_sklearn = evaluate_model(y_test, y_pred_log_reg)\n",
    "results_manual = evaluate_model(y_test, y_pred_manual_log_reg)\n",
    "\n",
    "# Exibir resultados\n",
    "missing_values, statistics, results_sklearn, results_manual"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1ee45c-dae2-4e02-8fcb-899902f882a4",
   "metadata": {},
   "source": [
    "## Round 2\n",
    "After conducting some initial experiments, your team is not entirely satisfied with the obtained results. Several factors could be affecting the performance at this stage. One possible reason could be that the dataset size is too small, with insufficient assessed compounds. Another possible cause could be that the features used are not adequately descriptive. To address this, you request the feature engineers to extract additional features for the compounds. They have generated a new dataset, named `cruzi_comp_activity_structural_features.csv`, which includes the chemical substructures present in each compound that are known to be informative of biological activity.\n",
    "\n",
    "Your next task is to assess the effectiveness of these newly extracted features. It is crucial to determine if they improve the model's performance. You can experiment with both sets of features or even the combination of both. With these many algorithms and parameters to set, the validation set will be very important! Report the performance of each model on a held-out test set with relevant evaluation metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5c7e46fe-4b7c-43d0-98c7-fa83a6b6e700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CID</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>119</th>\n",
       "      <th>120</th>\n",
       "      <th>121</th>\n",
       "      <th>122</th>\n",
       "      <th>123</th>\n",
       "      <th>124</th>\n",
       "      <th>125</th>\n",
       "      <th>126</th>\n",
       "      <th>127</th>\n",
       "      <th>EC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1201</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3793</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7573</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17520</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31316</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3842</th>\n",
       "      <td>56642840</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3843</th>\n",
       "      <td>56642874</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3844</th>\n",
       "      <td>56642875</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3845</th>\n",
       "      <td>56642931</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3846</th>\n",
       "      <td>56642953</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.876</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3847 rows × 130 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           CID  0  1  2  3  4  5  6  7  8  ...  119  120  121  122  123  124  \\\n",
       "0         1201  1  0  1  1  1  0  1  0  0  ...    1    1    1    1    0    0   \n",
       "1         3793  1  0  1  1  1  1  1  1  1  ...    0    1    1    0    1    1   \n",
       "2         7573  1  0  0  0  1  1  1  0  0  ...    1    0    0    0    0    1   \n",
       "3        17520  0  0  1  0  1  1  0  0  0  ...    0    0    1    0    0    0   \n",
       "4        31316  1  0  1  1  1  1  0  0  1  ...    1    1    0    0    0    1   \n",
       "...        ... .. .. .. .. .. .. .. .. ..  ...  ...  ...  ...  ...  ...  ...   \n",
       "3842  56642840  1  1  1  1  1  0  1  0  1  ...    1    0    0    0    1    0   \n",
       "3843  56642874  1  1  1  1  1  0  1  0  1  ...    0    1    0    1    1    0   \n",
       "3844  56642875  1  0  1  0  1  0  0  0  1  ...    0    0    0    0    1    0   \n",
       "3845  56642931  1  1  1  0  1  0  1  0  1  ...    0    1    0    1    0    0   \n",
       "3846  56642953  1  0  1  1  1  1  1  0  1  ...    1    1    1    1    1    0   \n",
       "\n",
       "      125  126  127   EC50  \n",
       "0       1    1    0  2.280  \n",
       "1       0    1    0  0.100  \n",
       "2       0    0    0  2.524  \n",
       "3       1    0    0  0.524  \n",
       "4       0    0    0  2.112  \n",
       "...   ...  ...  ...    ...  \n",
       "3842    1    0    1  2.415  \n",
       "3843    0    1    0  0.663  \n",
       "3844    0    0    0  0.141  \n",
       "3845    0    0    0  0.854  \n",
       "3846    1    0    0  2.876  \n",
       "\n",
       "[3847 rows x 130 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the dataset\n",
    "struct_df = pd.read_csv('cruzi_comp_activity_structural_features.csv')\n",
    "struct_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e607954f-c577-4426-b89b-2eee579ef040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar o dataset original\n",
    "mol_df = pd.read_csv('cruzi_comp_activity_molecular_features.csv')\n",
    "\n",
    "# Verificar valores ausentes e estatísticas básicas\n",
    "missing_values = mol_df.isnull().sum()\n",
    "statistics = mol_df.describe()\n",
    "\n",
    "# Tratar valores ausentes imputando com a média de cada coluna\n",
    "mol_df['NumberOfAromaticRings'].fillna(mol_df['NumberOfAromaticRings'].mean(), inplace=True)\n",
    "mol_df['TPSA'].fillna(mol_df['TPSA'].mean(), inplace=True)\n",
    "\n",
    "# Criar uma variável alvo binária\n",
    "mol_df['Active'] = mol_df['EC50'] <= 1\n",
    "\n",
    "# Carregar o novo conjunto de dados de estruturas\n",
    "struct_df = pd.read_csv('cruzi_comp_activity_structural_features.csv')\n",
    "\n",
    "# Usar 'CID' como a coluna comum para mesclagem\n",
    "common_column = 'CID'\n",
    "\n",
    "# Verificar se a coluna comum está presente em ambos os datasets\n",
    "if common_column in mol_df.columns and common_column in struct_df.columns:\n",
    "    # Combinar os dois conjuntos de dados baseando-se no identificador comum\n",
    "    combined_df = pd.merge(mol_df, struct_df, on=common_column)\n",
    "else:\n",
    "    raise KeyError(f\"A coluna '{common_column}' não está presente em um dos datasets.\")\n",
    "\n",
    "# Verificar valores ausentes\n",
    "print(combined_df.isnull().sum())\n",
    "\n",
    "# Tratar valores ausentes, se necessário\n",
    "combined_df.fillna(combined_df.mean(), inplace=True)\n",
    "\n",
    "# Preparar os dados para o modelo\n",
    "X_combined = combined_df.drop(columns=['EC50', 'Active', common_column])\n",
    "y_combined = combined_df['Active']\n",
    "\n",
    "# Dividir os dados em treino, validação e teste\n",
    "X_train_combined, X_temp_combined, y_train_combined, y_temp_combined = train_test_split(X_combined, y_combined, test_size=0.3, random_state=42)\n",
    "X_val_combined, X_test_combined, y_val_combined, y_test_combined = train_test_split(X_temp_combined, y_temp_combined, test_size=0.5, random_state=42)\n",
    "\n",
    "# Padronizar as features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_combined)\n",
    "X_val_scaled = scaler.transform(X_val_combined)\n",
    "X_test_scaled = scaler.transform(X_test_combined)\n",
    "\n",
    "# Função para avaliar o modelo\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    return {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1_score': f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# Função para treinar e avaliar modelos\n",
    "def train_and_evaluate(models, X_train, y_train, X_val, y_val):\n",
    "    results = {}\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        results[name] = evaluate_model(y_val, y_pred)\n",
    "    return results\n",
    "\n",
    "# Modelos a serem testados\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'k-Nearest Neighbors': KNeighborsClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Neural Network': MLPClassifier(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4989a0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avaliar modelos usando os recursos antigos\n",
    "X_train_old = mol_df.drop(columns=['EC50', 'Active', 'CID'])\n",
    "y_train_old = mol_df['Active']\n",
    "X_train_old_scaled = scaler.fit_transform(X_train_old)\n",
    "results_old_features = train_and_evaluate(models, X_train_old_scaled, y_train_old, X_val_scaled, y_val_combined)\n",
    "\n",
    "# Avaliar modelos usando os novos recursos\n",
    "X_train_new = struct_df.drop(columns=['EC50', 'Active', 'CID'])\n",
    "y_train_new = struct_df['Active']\n",
    "X_train_new_scaled = scaler.fit_transform(X_train_new)\n",
    "results_new_features = train_and_evaluate(models, X_train_new_scaled, y_train_combined, X_val_scaled, y_val_combined)\n",
    "\n",
    "# Avaliar modelos usando a combinação de ambos os conjuntos de recursos\n",
    "results_combined_features = train_and_evaluate(models, X_train_scaled, y_train_combined, X_val_scaled, y_val_combined)\n",
    "\n",
    "# Organizar os resultados em um DataFrame\n",
    "results_df = pd.DataFrame({\n",
    "    'Method': ['Logistic Regression', 'k-Nearest Neighbors', 'Decision Tree', 'Neural Network'],\n",
    "    'Old Features': [results_old_features[model]['accuracy'] for model in models.keys()],\n",
    "    'New Features': [results_new_features[model]['accuracy'] for model in models.keys()],\n",
    "    'Combined Features': [results_combined_features[model]['accuracy'] for model in models.keys()]\n",
    "})\n",
    "\n",
    "print(results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff2ce9",
   "metadata": {},
   "source": [
    "Below is a markdown example of how you can report the results! Feel free to modify it to your liking!\n",
    "\n",
    "| **Method**        | **Metric 1** | **Metric 2** | **Metric 3** | **...** |\n",
    "|-------------------|--------------|--------------|--------------|---------|\n",
    "| **Log Reg**       |              |              |              |         |\n",
    "| **KNN**           |              |              |              |         |\n",
    "| **Neural Nets**   |              |              |              |         |\n",
    "| **Random Forest** |              |              |              |         |\n",
    "| **...**           |              |              |              |         |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
