{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "425ac6e9-8919-4c06-be1c-782241f835f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc6f6b7d-1fdf-43a4-bd7c-03d90114d3fb",
   "metadata": {},
   "source": [
    "# Lab 4 - Multi-layer Perceptron Forward Pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c353aba0-7656-45d0-961a-850e9f31f967",
   "metadata": {},
   "source": [
    "## Part I\n",
    "For this exercise you will implement a simple 2-layer perceptron (forward pass)\n",
    "\n",
    "For the first part you'll write a function that computes the forward pass of a 2-layer perecptron that predicts the prices of houses, using the usual Boston housing dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7804bef6-2bd6-4d05-bc4e-f9d8325f12ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio       b  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.read_csv('BostonHousing.csv')\n",
    "boston"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc1af35-c3bc-48b5-916a-63bf0dd535cb",
   "metadata": {
    "tags": []
   },
   "source": [
    "As usual, consider the MEDV as your target variable. \n",
    "* Split the data into training, validation and testing (70,15,15)% (you will need this for the next lab as we will build from this lab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5df5bfc8-26c0-4d48-9c3c-05a9e404e1d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Separate features (X) and target variable (y)\n",
    "X = boston.drop('medv', axis=1).values\n",
    "y = boston['medv'].values\n",
    "\n",
    "# Split the data into training, validation, and testing sets (70%, 15%, 15%)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1656b9eb-c272-43fb-8fe5-c095cf8461ad",
   "metadata": {},
   "source": [
    "Now you will write the function that computes the forward pass. \n",
    "* I provide here a structure that you can follow for your function, but again, feel free to modify it as you see fit.\n",
    "* Use the sigmoid function as the activation of the hidden layer.\n",
    "* Don't forget about the biases!\n",
    "* *It is up to you to think what should be the activation for the output layer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c582d2ac-e33c-47a7-8e24-fecadf38c53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_activation(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "30eb784e-a9c5-4a70-afcd-bcaf356aa576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def two_layer_perceptron(X, activation, dim_input, dim_hidden, dim_output):\n",
    "    \"\"\"\n",
    "    Implements the forward pass of a two-layer fully connected perceptron.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like\n",
    "        The input data\n",
    "    activation : function\n",
    "        The activation function to be used for the hidden layer\n",
    "    dim_input : int\n",
    "        The dimensionality of the input layer\n",
    "    dim_hidden : int\n",
    "        The dimensionality of the hidden layer\n",
    "    dim_output : int\n",
    "        The dimensionality of the output layer\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    y_pred : array-like\n",
    "        The output of the computation of the forward pass of the network\n",
    "    \"\"\"\n",
    "    # Initialize weights and biases\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    W1 = np.random.randn(dim_input, dim_hidden)\n",
    "    b1 = np.random.randn(dim_hidden)\n",
    "    W2 = np.random.randn(dim_hidden, dim_output)\n",
    "    b2 = np.random.randn(dim_output)\n",
    "\n",
    "    # Compute the activation of the hidden layer\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = activation(z1)\n",
    "\n",
    "    # Compute the activation of the output layer\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    # Assuming linear activation for the output layer (for regression)\n",
    "    # If you want to use a different activation function, you can modify it here\n",
    "    a2 = z2\n",
    "\n",
    "    # Return the predicted output\n",
    "    return a2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18eb5a0-15c8-4c98-8481-5ca52a27da2d",
   "metadata": {},
   "source": [
    "Calculate the RMSE of the forward pass. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "dcc26211-91c1-47f9-8779-eb723b0c209e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 22.088469252143494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dudda\\AppData\\Local\\Temp\\ipykernel_5772\\3596193989.py:2: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-z))\n"
     ]
    }
   ],
   "source": [
    "def calculate_rmse(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate the Root Mean Squared Error (RMSE) between predicted and true values.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_pred : array-like\n",
    "        Predicted values\n",
    "    y_true : array-like\n",
    "        True values\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rmse : float\n",
    "        The RMSE value\n",
    "    \"\"\"\n",
    "    rmse = np.sqrt(np.mean((y_pred - y_true)**2))\n",
    "    return rmse\n",
    "\n",
    "# Assuming you have the two_layer_perceptron function implemented and data prepared\n",
    "# Call the two_layer_perceptron function to get the predicted output\n",
    "y_pred = two_layer_perceptron(X_val, sigmoid_activation, dim_input=X_train.shape[1], dim_hidden=10, dim_output=1)\n",
    "\n",
    "# Calculate the RMSE using the predicted output and true target values\n",
    "rmse = calculate_rmse(y_pred, y_val)\n",
    "print(\"RMSE:\", rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6650ab-79e5-4636-a4c9-84b977c48541",
   "metadata": {},
   "source": [
    "## Part II \n",
    "\n",
    "For this exercise you will write a function that calculates the forward pass of a 2-layer perceptron that predicts the exact digit from a hand-written image, using the MNIST dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3bfe2473-16e8-4dce-9e5b-7d5ce1154200",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4f8f04ee-c8e6-4531-9ad4-b0e530e1f92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "digits = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6c49e3cd-e16a-4847-ac73-b9628f3f159a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = digits.data\n",
    "y = digits.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "172b3419-d470-433f-87f9-4df67e4761e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1797, 64)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebdaf177-1cda-4c04-8d12-090678310602",
   "metadata": {},
   "source": [
    "Again, you will split the data into training, validation and testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8519363c-f7e0-43a8-ba4e-a33ab9d5b96e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (1437, 64) (1437,)\n",
      "Validation set shape: (180, 64) (180,)\n",
      "Testing set shape: (180, 64) (180,)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "digits = load_digits()\n",
    "X = digits.data\n",
    "y = digits.target\n",
    "\n",
    "# Split the data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(\"Training set shape:\", X_train.shape, y_train.shape)\n",
    "print(\"Validation set shape:\", X_val.shape, y_val.shape)\n",
    "print(\"Testing set shape:\", X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc4d63e-30c3-4f7d-8f6f-b12496886b5e",
   "metadata": {},
   "source": [
    "Write a function that calculates the forward pass for this multi-class classification problem.\n",
    "* You will use the sigmoid activation function for the hidden layer.\n",
    "* For the output layer you will have to write the softmax activation function (you can check the slides)\n",
    "* __Note:__ you can easily re-use the function that you coded for Part I if you do a simple modification and also include an input argument for the activation of the output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "26d68da7-1fa1-4074-b8fa-29ff1c21d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    \"\"\"Softmax activation function\"\"\"\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True)) # Avoiding numerical instability\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "def forward_pass(X, W1, b1, W2, b2, output_activation='softmax'):\n",
    "    \"\"\"\n",
    "    Perform the forward pass of a 2-layer perceptron\n",
    "    \n",
    "    Parameters:\n",
    "        X (numpy.ndarray): Input data of shape (num_samples, num_features)\n",
    "        W1 (numpy.ndarray): Weights of the first layer of shape (num_features, hidden_units)\n",
    "        b1 (numpy.ndarray): Bias of the first layer of shape (hidden_units,)\n",
    "        W2 (numpy.ndarray): Weights of the second layer of shape (hidden_units, num_classes)\n",
    "        b2 (numpy.ndarray): Bias of the second layer of shape (num_classes,)\n",
    "        output_activation (str): Activation function for the output layer. Options: 'sigmoid', 'softmax'\n",
    "    \n",
    "    Returns:\n",
    "        numpy.ndarray: Output predictions of shape (num_samples, num_classes)\n",
    "    \"\"\"\n",
    "    # Forward pass through the first layer\n",
    "    z1 = np.dot(X, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    # Forward pass through the second layer\n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    \n",
    "    # Apply activation function for the output layer\n",
    "    if output_activation == 'sigmoid':\n",
    "        output = sigmoid(z2)\n",
    "    elif output_activation == 'softmax':\n",
    "        output = softmax(z2)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid output_activation. Choose 'sigmoid' or 'softmax'.\")\n",
    "    \n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6b264d-1b1d-433a-98d3-eaf33b685a67",
   "metadata": {},
   "source": [
    "Lastly, calculate the error of this forward pass using the cross-entropy loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "015f701c-f816-4208-8cdc-4ba32f03f08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-entropy loss on validation set: 2309.553442617581\n"
     ]
    }
   ],
   "source": [
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss\n",
    "    \n",
    "    Parameters:\n",
    "        y_pred (numpy.ndarray): Predicted probabilities of shape (num_samples, num_classes)\n",
    "        y_true (numpy.ndarray): True labels of shape (num_samples,)\n",
    "    \n",
    "    Returns:\n",
    "        float: Cross-entropy loss\n",
    "    \"\"\"\n",
    "    # Clip probabilities to avoid log(0) = -inf\n",
    "    y_pred = np.clip(y_pred, 1e-15, 1 - 1e-15)\n",
    "    \n",
    "    # Calculate cross-entropy loss\n",
    "    loss = -np.mean(np.sum(y_true * np.log(y_pred), axis=1))\n",
    "    \n",
    "    return loss\n",
    "\n",
    "\n",
    "# Assuming you have already performed the forward pass and obtained predictions\n",
    "# y_pred = forward_pass(X_val, W1, b1, W2, b2, output_activation='softmax')\n",
    "\n",
    "# Calculate cross-entropy loss on the validation set\n",
    "loss = cross_entropy_loss(y_pred, y_val)\n",
    "print(\"Cross-entropy loss on validation set:\", loss)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
